# HLD-14: Caching Strategies (Part 1)

---

## ğŸ“‹ Table of Contents
1. [Introduction](#introduction)
2. [What is Caching](#what-is-caching)
3. [Types of Caching](#types-of-caching)
4. [Distributed Caching](#distributed-caching)
5. [Caching Strategies](#caching-strategies)
6. [Summary](#summary)
7. [Interview Tips](#interview-tips)

---

## Introduction

**Topic:** Caching Strategies (Part 1)

**Coverage:**
- âœ… What is caching & benefits
- âœ… Types of caching (layers)
- âœ… Distributed caching
- âœ… 5 Caching strategies with sequence diagrams
  - Cache-Aside
  - Read-Through
  - Write-Around
  - Write-Through
  - Write-Back (Write-Behind)

**Part 2 will cover:**
- Cache eviction policies

---

## What is Caching

### Definition

```
Caching = Technique to store frequently used data
          in fast-access memory
          instead of slow-access memory
```

**Memory Speed Hierarchy:**

```
Fast Access Memory:
â”œâ”€ CPU Cache (L1, L2, L3)
â”œâ”€ RAM
â””â”€ In-memory stores (Redis, Memcached)

Slow Access Memory:
â”œâ”€ Hard Disk (HDD)
â”œâ”€ SSD
â””â”€ Database
```

**Example:**

```
WITHOUT Cache:
Request â†’ App â†’ Database (100ms)
Total: 100ms

WITH Cache:
Request â†’ App â†’ Cache (1ms)
Total: 1ms

100x faster! âœ“
```

---

### Benefits

#### 1. Makes System Fast

```
Reduced Latency:
- Cache read: 1-5ms
- DB read: 50-100ms

Result: Faster response times
```

#### 2. Fault Tolerance

```
Scenario: DB goes down

WITHOUT Cache:
All requests fail âœ—

WITH Cache (Write-Back strategy):
Requests served from cache âœ“
System remains available
```

**Note:** Fault tolerance depends on caching strategy (covered in Write-Back section)

---

## Types of Caching

### Caching at Different Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Client Side                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Browser Cache              â”‚   â”‚
â”‚  â”‚   - HTML, CSS, JS, Images    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CDN Layer                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   CDN Cache                  â”‚   â”‚
â”‚  â”‚   - Static content           â”‚   â”‚
â”‚  â”‚   - Geo-distributed          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Load Balancer Layer            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Load Balancer Cache        â”‚   â”‚
â”‚  â”‚   - L7 load balancers        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Application Layer              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Server-Side Cache          â”‚   â”‚
â”‚  â”‚   - Redis, Memcached         â”‚   â”‚
â”‚  â”‚   - Application cache        â”‚   â”‚ â† Focus of this lecture
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Database Layer                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Database Cache             â”‚   â”‚
â”‚  â”‚   - Query cache              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Server-Side Application Cache

**Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Load     â”‚
â”‚  Balancer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App    â”‚ â”‚ App    â”‚ â”‚ App    â”‚ â”‚ App    â”‚
â”‚Server 1â”‚ â”‚Server 2â”‚ â”‚Server 3â”‚ â”‚Server Nâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚          â”‚          â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Cache  â”‚ â† Redis, Memcached
         â”‚ (Redis) â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   DB    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Flow:**

```
1. Client â†’ Load Balancer
2. Load Balancer â†’ App Server
3. App Server â†’ Cache (check first)
4. If cache miss â†’ DB
5. Update cache
6. Return to client
```

---

## Distributed Caching

### Problem: Single Cache Server

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App 1  â”‚  â”‚ App 2  â”‚  â”‚ App 3  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚           â”‚           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Cache  â”‚ â† Single point of failure!
          â”‚ Server  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Problems:
âŒ Limited scalability
âŒ Single point of failure
âŒ Limited resources
```

---

### Solution: Distributed Cache

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App 1  â”‚  â”‚ App 2  â”‚  â”‚ App 3  â”‚
â”‚Cache   â”‚  â”‚Cache   â”‚  â”‚Cache   â”‚
â”‚Client  â”‚  â”‚Client  â”‚  â”‚Client  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚           â”‚           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Cache Pool   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼           â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Cache 1 â”‚  â”‚Cache 2 â”‚  â”‚Cache 3 â”‚  â”‚Cache N â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Benefits:
âœ“ Scalable (add more servers)
âœ“ No single point of failure
âœ“ Distributed load
```

---

### Consistent Hashing

**How Cache Server is Selected:**

```
Consistent Hashing Ring:

                    Cache 2
                       â—
                   â•±       â•²
              â•±               â•²
         â•±                       â•²
    â—                               â—
Cache 1                         Cache 3
    â”‚                               â”‚
    â”‚                               â”‚
    â”‚       Request (hash)          â”‚
    â”‚            â—                  â”‚
    â”‚            â”‚                  â”‚
    â”‚            â””â”€â–º Clockwise      â”‚
    â”‚               rotation        â”‚
    â”‚               First server    â”‚
    â”‚               = Cache 3       â”‚
    â—                               â—
Cache 5                         Cache 4
         â•²                       â•±
              â•²               â•±
                   â•²       â•±
                       â—

Process:
1. Hash the request key
2. Find position on ring
3. Move clockwise
4. First cache server = Selected
```

**Example:**

```
Request: GET user:123

1. Hash("user:123") â†’ Position on ring
2. Rotate clockwise
3. First cache server: Cache 3
4. Store/Retrieve from Cache 3
```

**Note:** For in-depth consistent hashing, see HLD-06 video

---

## Caching Strategies

### Overview

```
5 Caching Strategies:

READ Strategies:
1. Cache-Aside (Lazy Loading)
2. Read-Through

WRITE Strategies:
3. Write-Around
4. Write-Through
5. Write-Back (Write-Behind)
```

---

### 1. Cache-Aside (Lazy Loading)

#### How It Works

```
READ Flow:

Client                App               Cache              DB
  â”‚                    â”‚                  â”‚                 â”‚
  â”‚â”€â”€â”€â”€ GET â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚                 â”‚
  â”‚                    â”‚                  â”‚                 â”‚
  â”‚                    â”‚â”€â”€â”€â”€ Check â”€â”€â”€â”€â”€â”€â–ºâ”‚                 â”‚
  â”‚                    â”‚                  â”‚                 â”‚
  â”‚                    â”‚â—„â”€â”€â”€â”€ Hit/Miss â”€â”€â”€â”‚                 â”‚
  â”‚                    â”‚                  â”‚                 â”‚
  â”‚                    â”‚                                    â”‚
  â”‚                    â”‚ If HIT:                            â”‚
  â”‚                    â”‚â—„â”€â”€â”€â”€ Data â”€â”€â”€â”€â”€â”€â”€â”‚                 â”‚
  â”‚â—„â”€â”€â”€â”€ Response â”€â”€â”€â”€â”€â”‚                  â”‚                 â”‚
  â”‚                    â”‚                                    â”‚
  â”‚                    â”‚ If MISS:                           â”‚
  â”‚                    â”‚â”€â”€â”€â”€ Fetch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚
  â”‚                    â”‚                  â”‚                 â”‚
  â”‚                    â”‚â—„â”€â”€â”€â”€ Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
  â”‚                    â”‚                  â”‚                 â”‚
  â”‚                    â”‚â”€â”€â”€â”€ Update â”€â”€â”€â”€â”€â–ºâ”‚                 â”‚
  â”‚                    â”‚                  â”‚                 â”‚
  â”‚â—„â”€â”€â”€â”€ Response â”€â”€â”€â”€â”€â”‚                  â”‚                 â”‚
  â”‚                    â”‚                  â”‚                 â”‚
```

**Step-by-Step:**

```
1. Client sends GET request
2. App checks cache
3. Cache Hit:
   - Return data from cache
   - Fast! âœ“
4. Cache Miss:
   - Fetch from DB
   - Update cache
   - Return data
```

---

#### Sequence Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ Client â”‚    â”‚   App   â”‚    â”‚ Cache â”‚    â”‚  DB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚              â”‚            â”‚
     â”‚â”€â”€â”€ GET â”€â”€â”€â”€â–ºâ”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Read â”€â”€â”€â”€â–ºâ”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â—„â”€â”€â”€ Data â”€â”€â”€â”€â”‚            â”‚
     â”‚             â”‚   (Cache Hit)â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚â—„â”€â”€ Data â”€â”€â”€â”€â”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     
     
     â”‚â”€â”€â”€ GET â”€â”€â”€â”€â–ºâ”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Read â”€â”€â”€â”€â–ºâ”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â—„â”€â”€â”€ Miss â”€â”€â”€â”€â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Fetch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â—„â”€â”€â”€ Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Write â”€â”€â”€â–ºâ”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚â—„â”€â”€ Data â”€â”€â”€â”€â”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
```

---

#### Advantages

**1. Good for Read-Heavy Applications**

```
Scenario: News website

Reads: 10,000 requests/sec
Writes: 10 requests/sec

Cache-Aside:
- Most reads from cache (fast)
- Few writes to DB
- Perfect fit âœ“
```

**2. Cache Failure Doesn't Break System**

```
Cache goes down:

Request â†’ App â†’ Cache âœ— (Down)
                â”‚
                â””â”€â–º Treated as cache miss
                    Fetch from DB âœ“
                    System still works!

Resilient âœ“
```

**3. Independent Cache Data Model**

```
DB Structure:
Table: Employee
â”œâ”€ id
â”œâ”€ name
â”œâ”€ address
â”œâ”€ dept_id

Table: Salary
â”œâ”€ emp_id
â”œâ”€ amount
â”œâ”€ currency

Cache Structure:
Key: employee:123
Value: {
  "id": 123,
  "name": "John",
  "address": "NYC",
  "salary": {
    "amount": 50000,
    "currency": "USD"
  }
}

App controls cache structure âœ“
Can denormalize, combine tables
Optimized for reads
```

---

#### Disadvantages

**1. New Data Always Cache Miss**

```
Timeline:

T0: POST /users (create user:456)
    â†’ Writes to DB only
    â†’ Cache not updated

T1: GET /users/456
    â†’ Check cache: Miss âœ—
    â†’ Fetch from DB
    â†’ Update cache
    â†’ Return data

First read always slow
```

**2. Inconsistency Risk**

```
Problem: Stale data in cache

Timeline:

T0: GET user:123
    Cache: Miss
    DB: value = 10
    Cache updated: value = 10 âœ“

T1: PUT user:123 (update to 11)
    DB updated: value = 11 âœ“
    Cache NOT updated âœ—

T2: GET user:123
    Cache: Hit (value = 10) âœ— STALE!
    DB: value = 11
    
Inconsistency! Cache has old data
```

**Visual:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ Cache â”‚         â”‚  DB  â”‚
â”‚       â”‚         â”‚      â”‚
â”‚ v=10  â”‚         â”‚ v=10 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”˜
                     â†“
                  PUT v=11
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ Cache â”‚         â”‚  DB  â”‚
â”‚       â”‚         â”‚      â”‚
â”‚ v=10  â”‚ âœ—       â”‚ v=11 â”‚ âœ“
â”‚(Stale)â”‚         â”‚(Fresh)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”˜

Solution: Use with Write-Around or Write-Through
```

---

### 2. Read-Through Cache

#### How It Works

```
Similar to Cache-Aside, but:
- Cache library handles DB fetch
- App doesn't manage cache updates
```

**Sequence Diagram:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ Client â”‚    â”‚   App   â”‚    â”‚Cache Lib  â”‚    â”‚  DB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚                â”‚              â”‚
     â”‚â”€â”€â”€ GET â”€â”€â”€â”€â–ºâ”‚                â”‚              â”‚
     â”‚             â”‚                â”‚              â”‚
     â”‚             â”‚â”€â”€â”€ Read â”€â”€â”€â”€â”€â”€â–ºâ”‚              â”‚
     â”‚             â”‚                â”‚              â”‚
     â”‚             â”‚                â”‚              â”‚
     â”‚             â”‚   Cache Hit:   â”‚              â”‚
     â”‚             â”‚â—„â”€â”€â”€ Data â”€â”€â”€â”€â”€â”€â”‚              â”‚
     â”‚             â”‚                â”‚              â”‚
     â”‚â—„â”€â”€ Data â”€â”€â”€â”€â”‚                â”‚              â”‚
     â”‚             â”‚                â”‚              â”‚
     
     â”‚â”€â”€â”€ GET â”€â”€â”€â”€â–ºâ”‚                â”‚              â”‚
     â”‚             â”‚                â”‚              â”‚
     â”‚             â”‚â”€â”€â”€ Read â”€â”€â”€â”€â”€â”€â–ºâ”‚              â”‚
     â”‚             â”‚                â”‚              â”‚
     â”‚             â”‚   Cache Miss:  â”‚              â”‚
     â”‚             â”‚                â”‚â”€â”€â”€ Fetch â”€â”€â”€â–ºâ”‚
     â”‚             â”‚                â”‚              â”‚
     â”‚             â”‚                â”‚â—„â”€â”€â”€ Data â”€â”€â”€â”€â”‚
     â”‚             â”‚                â”‚              â”‚
     â”‚             â”‚                â”‚ (Updates     â”‚
     â”‚             â”‚                â”‚  itself)     â”‚
     â”‚             â”‚                â”‚              â”‚
     â”‚             â”‚â—„â”€â”€â”€ Data â”€â”€â”€â”€â”€â”€â”‚              â”‚
     â”‚             â”‚                â”‚              â”‚
     â”‚â—„â”€â”€ Data â”€â”€â”€â”€â”‚                â”‚              â”‚
     â”‚             â”‚                â”‚              â”‚
```

**Key Difference:**

```
Cache-Aside:
App handles:
- Check cache
- Fetch from DB (if miss)
- Update cache

Read-Through:
Cache library handles:
- Check cache
- Fetch from DB (if miss)
- Update cache

App just calls cache.get(key)
```

---

#### Advantages

**1. Good for Read-Heavy Applications**

```
Same as Cache-Aside
Optimized for reads
```

**2. Separation of Concerns**

```
App code:
data = cache.get("user:123")
// That's it!

Cache library handles:
- Cache hit/miss logic
- DB fetch
- Cache update

Cleaner code âœ“
```

---

#### Disadvantages

**1. New Data Always Cache Miss**

```
Same as Cache-Aside
First read always slow
```

**2. Inconsistency Risk**

```
Same as Cache-Aside
Needs write strategy
```

**3. Cache Structure = DB Structure**

```
DB Table:
Employee (id, name, address, dept, salary, ...)
20 fields

Cache:
Key: employee:123
Value: {
  "id": 123,
  "name": "John",
  "address": "NYC",
  "dept": "Engineering",
  "salary": 50000,
  ... (all 20 fields)
}

1:1 mapping with DB âœ—
Cannot customize structure
Cannot denormalize
```

---

### 3. Write-Around Cache

#### How It Works

```
Write Strategy:
- Write directly to DB
- Don't update cache
- Invalidate cache entry (mark dirty)
```

**Sequence Diagram:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ Client â”‚    â”‚   App   â”‚    â”‚ Cache â”‚    â”‚  DB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚              â”‚            â”‚
     â”‚â”€â”€â”€ PUT â”€â”€â”€â”€â–ºâ”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Write â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â—„â”€â”€â”€ OK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Invalidateâ”‚            â”‚
     â”‚             â”‚   (mark dirty)           â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚â—„â”€â”€ OK â”€â”€â”€â”€â”€â”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     
Next GET:
     â”‚â”€â”€â”€ GET â”€â”€â”€â”€â–ºâ”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Read â”€â”€â”€â”€â–ºâ”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â—„â”€â”€â”€ Dirty â”€â”€â”€â”‚            â”‚
     â”‚             â”‚   (Cache Miss)           â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Fetch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â—„â”€â”€â”€ Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Update â”€â”€â–ºâ”‚            â”‚
     â”‚             â”‚   (fresh data)           â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚â—„â”€â”€ Data â”€â”€â”€â”€â”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
```

**Example:**

```
Initial State:
Cache: user:123 = {value: 10}
DB: user:123 = {value: 10}

PUT user:123 (value: 11):
1. Write to DB: value = 11 âœ“
2. Invalidate cache: dirty = true

State After PUT:
Cache: user:123 = {value: 10, dirty: true}
DB: user:123 = {value: 11}

GET user:123:
1. Check cache: dirty = true â†’ Cache Miss
2. Fetch from DB: value = 11
3. Update cache: value = 11, dirty = false
4. Return: 11 âœ“
```

---

#### Advantages

**1. Good for Read-Heavy Applications**

```
Used WITH Cache-Aside or Read-Through
Solves inconsistency problem
```

**2. Resolves Inconsistency**

```
Write-Around ensures:
- Writes go to DB
- Cache invalidated
- Next read gets fresh data

No stale data âœ“
```

---

#### Disadvantages

**1. New Data Always Cache Miss**

```
POST /users (new user)
â†’ Writes to DB only
â†’ Cache not touched

GET /users/new
â†’ Cache miss
â†’ Fetch from DB
```

**2. Not Fault Tolerant**

```
DB goes down:

PUT request â†’ DB âœ— (Down)
              Write fails âœ—

System unavailable for writes âœ—
```

**Visual:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   App   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ PUT request
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DB    â”‚
â”‚  âœ— DOWN â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Write fails âœ—
No fault tolerance
```

---

### 4. Write-Through Cache

#### How It Works

```
Write Strategy:
1. Write to cache first
2. Write to DB synchronously
3. Both must succeed (2-phase commit)
```

**Sequence Diagram:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ Client â”‚    â”‚   App   â”‚    â”‚ Cache â”‚    â”‚  DB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚              â”‚            â”‚
     â”‚â”€â”€â”€ POST â”€â”€â”€â–ºâ”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Write â”€â”€â”€â–ºâ”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â—„â”€â”€â”€ OK â”€â”€â”€â”€â”€â”€â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Write â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
     â”‚             â”‚   (Synchronous)          â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â—„â”€â”€â”€ OK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚â—„â”€â”€ OK â”€â”€â”€â”€â”€â”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     
If DB fails:
     â”‚â”€â”€â”€ POST â”€â”€â”€â–ºâ”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Write â”€â”€â”€â–ºâ”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â—„â”€â”€â”€ OK â”€â”€â”€â”€â”€â”€â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Write â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â—„â”€â”€â”€ FAIL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚             â”‚â”€â”€â”€ Rollbackâ–ºâ”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
     â”‚â—„â”€â”€ FAIL â”€â”€â”€â”€â”‚              â”‚            â”‚
     â”‚             â”‚              â”‚            â”‚
```

**Example:**

```
POST user:123 (value: 10):

1. Write to cache: value = 10 âœ“
2. Write to DB: value = 10 âœ“
3. Both succeed â†’ Return success

State:
Cache: user:123 = {value: 10}
DB: user:123 = {value: 10}
Consistent! âœ“


POST user:456 (value: 20):

1. Write to cache: value = 20 âœ“
2. Write to DB: FAIL âœ—
3. Rollback cache
4. Return failure

State:
Cache: user:456 = (not present)
DB: user:456 = (not present)
Consistent! âœ“
```

---

#### Advantages

**1. Cache and DB Always Consistent**

```
2-Phase Commit:
- Both succeed â†’ Consistent
- Either fails â†’ Rollback â†’ Consistent

No stale data âœ“
```

**2. Increased Cache Hits**

```
POST user:123 (new user)
â†’ Written to cache âœ“
â†’ Written to DB âœ“

GET user:123
â†’ Cache hit! âœ“
â†’ Fast response

Even new data in cache
```

---

#### Disadvantages

**1. Cannot Use Alone**

```
Write-Through alone:
- Writes to cache + DB
- But who reads from cache?

Need read strategy:
- Cache-Aside OR
- Read-Through

Otherwise just added latency âœ—
```

**2. Two-Phase Commit Required**

```
Complexity:
- Transaction management
- Rollback logic
- Error handling

Implementation overhead
```

**3. Not Fully Fault Tolerant**

```
Cache goes down:
POST â†’ Cache âœ— (Down)
       Write fails âœ—

DB goes down:
POST â†’ Cache âœ“
       DB âœ— (Down)
       Rollback cache
       Write fails âœ—

Either down â†’ Writes fail âœ—
```

---

### 5. Write-Back (Write-Behind) Cache

#### How It Works

```
Write Strategy:
1. Write to cache
2. Queue write to DB (asynchronous)
3. Return success immediately
4. DB write happens later
```

**Sequence Diagram:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ Client â”‚  â”‚   App   â”‚  â”‚ Cache â”‚  â”‚ Queue â”‚  â”‚  DB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
     â”‚           â”‚            â”‚          â”‚          â”‚
     â”‚â”€ POST â”€â”€â”€â–ºâ”‚            â”‚          â”‚          â”‚
     â”‚           â”‚            â”‚          â”‚          â”‚
     â”‚           â”‚â”€ Write â”€â”€â”€â–ºâ”‚          â”‚          â”‚
     â”‚           â”‚            â”‚          â”‚          â”‚
     â”‚           â”‚â—„â”€ OK â”€â”€â”€â”€â”€â”€â”‚          â”‚          â”‚
     â”‚           â”‚            â”‚          â”‚          â”‚
     â”‚           â”‚â”€ Publish â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚          â”‚
     â”‚           â”‚            â”‚          â”‚          â”‚
     â”‚â—„â”€ OK â”€â”€â”€â”€â”€â”‚            â”‚          â”‚          â”‚
     â”‚           â”‚            â”‚          â”‚          â”‚
     
     (Async - later)
                              â”‚          â”‚          â”‚
                              â”‚          â”‚â”€ Write â”€â–ºâ”‚
                              â”‚          â”‚          â”‚
                              â”‚          â”‚â—„â”€ OK â”€â”€â”€â”€â”‚
                              â”‚          â”‚          â”‚
```

**Example:**

```
POST user:123 (value: 10):

1. Write to cache: value = 10 âœ“
2. Publish to queue: {write user:123, value: 10}
3. Return success immediately âœ“

State (immediately):
Cache: user:123 = {value: 10}
Queue: [write user:123 = 10]
DB: (not updated yet)

State (after async processing):
Cache: user:123 = {value: 10}
Queue: []
DB: user:123 = {value: 10}
```

---

#### Advantages

**1. Good for Write-Heavy Applications**

```
Scenario: Analytics logging

Writes: 10,000 events/sec
Reads: 100 queries/sec

Write-Back:
- All writes to cache (fast)
- Async DB writes (batched)
- No write bottleneck âœ“
```

**2. Reduced Write Latency**

```
Write-Through:
POST â†’ Cache (1ms) + DB (100ms) = 101ms

Write-Back:
POST â†’ Cache (1ms) + Queue (1ms) = 2ms

50x faster! âœ“
```

**3. Increased Cache Hits**

```
POST user:123
â†’ Cache updated immediately

GET user:123
â†’ Cache hit (latest data) âœ“

Always fresh data in cache
```

**4. Fault Tolerant**

```
DB goes down for 2 hours:

Writes:
â†’ Cache âœ“ (works)
â†’ Queue âœ“ (accumulates)
â†’ System available âœ“

Reads:
â†’ Cache âœ“ (has latest data)
â†’ System available âœ“

When DB comes back:
â†’ Queue processes backlog
â†’ DB catches up

Fault tolerant! âœ“
```

---

#### Disadvantages

**1. Data Loss Risk**

```
Problem: Cache TTL < DB downtime

Timeline:

T0: POST user:123 (value: 10)
    Cache: value = 10 (TTL: 3 hours)
    Queue: [write user:123 = 10]
    DB: (down)

T1 (1 hour): DB still down
             Queue trying to write

T2 (3 hours): Cache TTL expires
              Cache: (evicted)
              DB: still down
              Queue: still trying

T3 (5 hours): DB comes back
              Queue writes: value = 10
              But cache empty!

T4: GET user:123
    Cache: Miss
    DB: value = 10
    Cache updated

Risk period: T2 to T4
If app had cached value in memory â†’ Lost!
```

**Visual:**

```
Timeline:
T0        T1        T2        T3        T4
â”‚         â”‚         â”‚         â”‚         â”‚
POST      â”‚    Cacheâ”‚    DB   â”‚    GET  â”‚
          â”‚    TTL  â”‚   comes â”‚         â”‚
          â”‚   expiresâ”‚   back â”‚         â”‚
          â”‚         â”‚         â”‚         â”‚
Cache: 10 â”‚    10   â”‚   empty â”‚   empty â”‚   10
Queue: [10]   [10]     [10]      []       []
DB:    down   down     down      10       10
                      â†‘
                Data loss risk!
```

**2. Best Used With Read Strategy**

```
Write-Back alone:
- Fast writes âœ“
- But reads?

With Cache-Aside or Read-Through:
- Fast writes âœ“
- Fast reads âœ“
- Complete solution âœ“
```

---

## Summary

### Strategy Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Strategy   â”‚  Cache-  â”‚  Read-   â”‚  Write-  â”‚  Write-  â”‚  Write-  â”‚
â”‚              â”‚  Aside   â”‚ Through  â”‚  Around  â”‚ Through  â”‚   Back   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Type         â”‚   Read   â”‚   Read   â”‚  Write   â”‚  Write   â”‚  Write   â”‚
â”‚              â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
â”‚ App manages  â”‚   Yes    â”‚    No    â”‚   Yes    â”‚   Yes    â”‚   Yes    â”‚
â”‚ cache        â”‚          â”‚(library) â”‚          â”‚          â”‚          â”‚
â”‚              â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
â”‚ Consistency  â”‚   Risk   â”‚   Risk   â”‚   Good   â”‚Excellent â”‚   Good   â”‚
â”‚              â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
â”‚ Cache hits   â”‚  Medium  â”‚  Medium  â”‚  Medium  â”‚   High   â”‚   High   â”‚
â”‚ for new data â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
â”‚              â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
â”‚ Write        â”‚   N/A    â”‚   N/A    â”‚  Medium  â”‚   Slow   â”‚   Fast   â”‚
â”‚ latency      â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
â”‚              â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
â”‚ Fault        â”‚   Good   â”‚   Good   â”‚   Poor   â”‚   Poor   â”‚Excellent â”‚
â”‚ tolerance    â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
â”‚              â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
â”‚ Use alone    â”‚   Yes    â”‚   Yes    â”‚    No    â”‚    No    â”‚    No    â”‚
â”‚              â”‚          â”‚          â”‚          â”‚(need readâ”‚(need readâ”‚
â”‚              â”‚          â”‚          â”‚          â”‚strategy) â”‚strategy) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Common Combinations

```
1. Cache-Aside + Write-Around
   - Read-heavy apps
   - Consistency important
   - Simple implementation

2. Read-Through + Write-Through
   - Consistency critical
   - Library-managed cache
   - Transactional systems

3. Cache-Aside + Write-Back
   - Write-heavy apps
   - High performance needed
   - Fault tolerance required

4. Read-Through + Write-Back
   - Best performance
   - Library-managed
   - Complex implementation
```

---

### Decision Matrix

```
Choose based on:

Read-Heavy + Simple:
â†’ Cache-Aside + Write-Around

Read-Heavy + Library-managed:
â†’ Read-Through + Write-Around

Write-Heavy + Performance:
â†’ Cache-Aside + Write-Back

Consistency Critical:
â†’ Read-Through + Write-Through

Fault Tolerance Critical:
â†’ Cache-Aside + Write-Back
```

---

## Interview Tips

### Common Questions

**Q1: "Explain Cache-Aside strategy"**

```
Answer:
"Cache-Aside is a lazy loading strategy.

Read flow:
1. App checks cache
2. Cache hit â†’ Return data
3. Cache miss â†’ Fetch from DB, update cache, return

Advantages:
âœ“ Good for read-heavy apps
âœ“ Cache failure doesn't break system
âœ“ Custom cache structure

Disadvantages:
âœ— New data always cache miss
âœ— Inconsistency risk (needs write strategy)

Example: News website, product catalog"
```

**Q2: "Cache-Aside vs Read-Through?"**

```
Answer:
"Both are read strategies, key difference is who manages cache:

Cache-Aside:
- App handles cache logic
- App fetches from DB on miss
- App updates cache
- More control, more code

Read-Through:
- Cache library handles logic
- Library fetches from DB on miss
- Library updates cache
- Less code, less control

Trade-off:
Cache-Aside: Flexibility (custom cache structure)
Read-Through: Simplicity (1:1 DB mapping)

Choose Cache-Aside when need custom cache structure
Choose Read-Through when want simpler code"
```

**Q3: "How does Write-Back provide fault tolerance?"**

```
Answer:
"Write-Back is fault tolerant because writes don't depend on DB.

Normal flow:
1. Write to cache âœ“
2. Queue DB write (async)
3. Return success immediately

DB goes down:
1. Write to cache âœ“ (still works)
2. Queue accumulates writes
3. Reads from cache âœ“ (has latest data)
4. System remains available

When DB recovers:
- Queue processes backlog
- DB catches up

Tolerance window = Cache TTL
If cache TTL = 24 hours, can tolerate 24hr DB outage

Risk: If DB down > Cache TTL â†’ Data loss

Example: Analytics, logging systems"
```

**Q4: "Why can't Write-Through be used alone?"**

```
Answer:
"Write-Through only handles writes, not reads.

Write-Through alone:
POST â†’ Cache + DB âœ“
GET â†’ Where to read from? âœ—

Without read strategy:
- Cache updated but not read
- Just added latency
- No benefit

Must combine with:
- Cache-Aside OR
- Read-Through

Complete solution:
Writes: Write-Through (consistency)
Reads: Cache-Aside/Read-Through (performance)

Example:
Read-Through + Write-Through = Full consistency"
```

**Q5: "Explain inconsistency problem in Cache-Aside"**

```
Answer:
"Cache-Aside only handles reads, writes go directly to DB.

Problem scenario:

T0: GET user:123
    Cache miss â†’ Fetch from DB (value=10)
    Update cache (value=10)

T1: PUT user:123 (value=11)
    Update DB (value=11) âœ“
    Cache NOT updated âœ—

T2: GET user:123
    Cache hit (value=10) âœ— STALE!
    DB has value=11

Inconsistency: Cache stale, DB fresh

Solutions:
1. Write-Around: Invalidate cache on write
2. Write-Through: Update cache on write
3. TTL: Cache expires eventually
4. Manual invalidation: App invalidates on write

Best: Combine Cache-Aside with Write-Around or Write-Through"
```

### Key Points to Remember

```
1. Caching = Fast memory for frequent data

2. Benefits:
   - Faster response (low latency)
   - Fault tolerance (depends on strategy)
   - Reduced DB load

3. Distributed caching = Consistent hashing

4. 5 Strategies:
   READ: Cache-Aside, Read-Through
   WRITE: Write-Around, Write-Through, Write-Back

5. Cache-Aside:
   - App manages cache
   - Custom structure
   - Inconsistency risk

6. Read-Through:
   - Library manages cache
   - 1:1 DB mapping
   - Simpler code

7. Write-Around:
   - Write to DB, invalidate cache
   - Solves inconsistency
   - Not fault tolerant

8. Write-Through:
   - Write to cache + DB (sync)
   - Always consistent
   - Slower writes

9. Write-Back:
   - Write to cache, queue DB (async)
   - Fast writes
   - Fault tolerant
   - Data loss risk

10. Combine strategies:
    - Cache-Aside + Write-Around
    - Read-Through + Write-Through
    - Cache-Aside + Write-Back
```

### Do's âœ…

**1. Explain with Sequence Diagrams**
```
"Let me draw the flow:
Client â†’ App â†’ Cache â†’ DB
This helps visualize the strategy"
```

**2. Mention Trade-offs**
```
"Cache-Aside gives flexibility but requires more code.
Read-Through is simpler but less flexible."
```

**3. Give Real Examples**
```
"Cache-Aside: Product catalog (read-heavy)
Write-Back: Analytics logging (write-heavy)"
```

### Don'ts âŒ

**1. Don't Confuse Read and Write Strategies**
```
âŒ "Cache-Aside handles writes"
âœ“ "Cache-Aside is a read strategy"
```

**2. Don't Forget Combinations**
```
âŒ "Use Write-Through alone"
âœ“ "Combine Write-Through with read strategy"
```

**3. Don't Ignore Consistency**
```
âŒ "Cache-Aside is perfect"
âœ“ "Cache-Aside has inconsistency risk, needs write strategy"
```

---

**End of Lecture (Part 1)**

Caching is critical for system performance. Understanding the 5 strategies (Cache-Aside, Read-Through, Write-Around, Write-Through, Write-Back) and their trade-offs is essential. Remember: read strategies (Cache-Aside, Read-Through) handle reads, write strategies (Write-Around, Write-Through, Write-Back) handle writes. Combine them based on requirements: consistency, performance, or fault tolerance.

**Key Takeaway:** Cache-Aside for flexibility, Read-Through for simplicity, Write-Around for consistency, Write-Through for strong consistency, Write-Back for performance and fault tolerance. Always combine read + write strategies!

**Part 2 Preview:** Cache eviction policies (LRU, LFU, FIFO, etc.)
